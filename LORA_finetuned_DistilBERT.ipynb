{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from datasets import Dataset\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
        "from peft import get_peft_model, LoraConfig, TaskType"
      ],
      "metadata": {
        "id": "opFRJvCl1ggc"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the data"
      ],
      "metadata": {
        "id": "vzQFwcOdyLjz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv(\"train.csv\")\n",
        "val_df = pd.read_csv(\"validation.csv\")\n",
        "test_df = pd.read_csv(\"test.csv\")"
      ],
      "metadata": {
        "id": "KaIHY2DryJ2d"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenization of text"
      ],
      "metadata": {
        "id": "3PV1iR1PeZCD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_ckpt = \"distilbert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n",
        "\n",
        "# Create a mapping from status labels to integers\n",
        "label_map = {status: i for i, status in enumerate(train_df['status'].unique())}\n",
        "id_map = {i: status for i, status in enumerate(train_df['status'].unique())}\n",
        "print(id_map)\n",
        "\n",
        "def tokenize(batch):\n",
        "    # Map the status to numerical labels and add to the batch\n",
        "    batch[\"label\"] = [label_map[status] for status in batch[\"status\"]]\n",
        "    return tokenizer(batch[\"statement\"], padding=True, truncation=True)\n",
        "\n",
        "# Convert pandas DataFrames to Dataset objects\n",
        "train_dataset = Dataset.from_pandas(train_df)\n",
        "val_dataset = Dataset.from_pandas(val_df)\n",
        "test_dataset = Dataset.from_pandas(test_df)\n",
        "\n",
        "# Apply tokenization\n",
        "train_dataset_encoded = train_dataset.map(tokenize, batched=True)\n",
        "val_dataset_encoded = val_dataset.map(tokenize, batched=True)\n",
        "test_dataset_encoded = test_dataset.map(tokenize, batched=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 150,
          "referenced_widgets": [
            "a7d90b18669042c3a2615831c449bc4c",
            "15b47c6f92584d77838647d3717d4477",
            "07b522a539c7430695c9f0494bd31ca9",
            "059df714a7464c5eab9e13271c736060",
            "ffccf391a7cb4105b9781157f5ed0937",
            "87762153452f41d0868b99b4d8fe07f0",
            "b11f41254c884d549620be8586d33e38",
            "42bfb6919ec64dd5a22b1161dcf9ee3a",
            "cc5e4bf2813a48be8198d0b02455fdd6",
            "0d4e99d775e8443daa959605da10a007",
            "aea18894bf9c46ecaa65bc8e8fa161a2",
            "ac8390d71a38490194a7aceb747d049e",
            "027b01ac4f92422da0373de0f073c384",
            "1319db1ef7df4b508dcaecf040c00525",
            "9611407d395b4686b8dddfa4455be566",
            "be2fa60076744f2fa583114b188f0c9e",
            "b9b3d63869bc4b53900a98e6871c436a",
            "629b4824f0804cb79a13d529b8022ff4",
            "d832943e3fd249728034a6b723ef37e9",
            "9bcb650c62924f3cadfc41edfe8bf7e3",
            "269ae2cfc5be4153befe4fdb92e96a91",
            "8e28223985354a6ab97e73e050efcb0c",
            "5c87a010cc0c49108986bc3a3058980b",
            "b90502914ae54a669273c5f58fa07b4c",
            "cc21cad880074a7583ee65d169420e7b",
            "ea0f2eab511f4fe685958eb7bc017d36",
            "00444f91740b45368dea3e098092228b",
            "87dfe7f65eb5460bb352d428d7121ed3",
            "41072073f70b4ea985433cb6f36d22de",
            "a29d1047d0124063a456f4003e828304",
            "92f455295ecb491481a71066a581ca2b",
            "b00e21fe02484871b8b06433f2fddfdf",
            "9904b05b29844cacaf972751e39a5951"
          ]
        },
        "id": "sQWO3kDu0Awu",
        "outputId": "4f7041e6-b416-48fb-88c2-ecddd170bd4e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0: 'Personality disorder', 1: 'Suicidal', 2: 'Depression', 3: 'Anxiety', 4: 'Normal', 5: 'Stress', 6: 'Bipolar'}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/12360 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a7d90b18669042c3a2615831c449bc4c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1545 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ac8390d71a38490194a7aceb747d049e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1546 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5c87a010cc0c49108986bc3a3058980b"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model building"
      ],
      "metadata": {
        "id": "-nhwYpIngFMQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "base_model = AutoModelForSequenceClassification.from_pretrained(model_ckpt, num_labels=7)\n",
        "\n",
        "lora_config = LoraConfig(\n",
        "    r=8,\n",
        "    lora_alpha=16,\n",
        "    target_modules=[\"q_lin\", \"v_lin\"],\n",
        "    lora_dropout=0.1,\n",
        "    bias=\"none\",\n",
        "    task_type=TaskType.SEQ_CLS\n",
        ")\n",
        "\n",
        "model = get_peft_model(base_model, lora_config).to(device)\n",
        "model.print_trainable_parameters()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121,
          "referenced_widgets": [
            "677b95ed0784488e971d81eea5266166",
            "13225d3eae814f1cb1d2831e2310994a",
            "8053ff28baaa41dc99bae2d42709eaae",
            "5645fc27eb6441669ea9ccf8a88881a0",
            "cc99daa223e342b38d1ca063163e7621",
            "e92565f4e2fe4031ade3b9deff28756e",
            "2fc09db0e8d14613908b90c3009b5c80",
            "f0f76702a7834e7ea4c9239577960d98",
            "ec658bd23f0d4cc1be456689a95e0ae5",
            "8eeb2a51891d4da483b5fd6f8eb09c8e",
            "6d9984de558b4fdf9c4dab793103d22a"
          ]
        },
        "id": "4xdeXqig0A2q",
        "outputId": "72c93e13-f5e4-48d7-b9b4-87535196e739"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "677b95ed0784488e971d81eea5266166"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainable params: 743,431 || all params: 67,702,286 || trainable%: 1.0981\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "model_name = \"distilbert-LORA-finetuned-mental-health\"\n",
        "\n",
        "training_args = TrainingArguments(output_dir = model_name,\n",
        "                                  num_train_epochs=3,\n",
        "                                  learning_rate = 2e-5,\n",
        "                                  per_device_train_batch_size= batch_size,\n",
        "                                  per_device_eval_batch_size = batch_size,\n",
        "                                  weight_decay=0.01,\n",
        "                                  eval_strategy = 'epoch',\n",
        "                                  disable_tqdm=False,\n",
        "                                  report_to = \"none\")"
      ],
      "metadata": {
        "id": "G2OgXBPA0A5r"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define metrics"
      ],
      "metadata": {
        "id": "AHXLDBLOg6C1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(pred):\n",
        "  labels = pred.label_ids\n",
        "  preds = pred.predictions.argmax(-1)\n",
        "  f1 = f1_score(labels, preds, average='weighted')\n",
        "  acc = accuracy_score(labels, preds)\n",
        "  return {\"accuracy\": acc, \"f1\": f1}"
      ],
      "metadata": {
        "id": "RcNCOSmp0A9A"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train the model"
      ],
      "metadata": {
        "id": "uvzOZNlWpP5N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(model=model,\n",
        "                  args=training_args,\n",
        "                  compute_metrics=compute_metrics,\n",
        "                  train_dataset=train_dataset_encoded,\n",
        "                  eval_dataset=val_dataset_encoded,\n",
        "                  tokenizer=tokenizer)\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "q2lkZMMfhIGh",
        "outputId": "284bd45f-9e16-4800-9d20-c035a9ffd083"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-705617642.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(model=model,\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='582' max='582' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [582/582 24:38, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.605595</td>\n",
              "      <td>0.431068</td>\n",
              "      <td>0.361086</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.353621</td>\n",
              "      <td>0.519741</td>\n",
              "      <td>0.467818</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.565800</td>\n",
              "      <td>1.292137</td>\n",
              "      <td>0.535275</td>\n",
              "      <td>0.493285</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=582, training_loss=1.529619983791076, metrics={'train_runtime': 1481.7058, 'train_samples_per_second': 25.025, 'train_steps_per_second': 0.393, 'total_flos': 4997013171978240.0, 'train_loss': 1.529619983791076, 'epoch': 3.0})"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate performance on test data"
      ],
      "metadata": {
        "id": "KCP7qne_pOpw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preds_outputs = trainer.predict(test_dataset_encoded)\n",
        "preds_outputs.metrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "id": "GWDcMKKyyDWC",
        "outputId": "3c2af7a9-755b-496a-db0e-e9c126635801"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'test_loss': 1.3088897466659546,\n",
              " 'test_accuracy': 0.5394566623544631,\n",
              " 'test_f1': 0.499537248422549,\n",
              " 'test_runtime': 25.6583,\n",
              " 'test_samples_per_second': 60.253,\n",
              " 'test_steps_per_second': 0.974}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_preds = np.argmax(preds_outputs.predictions, axis=1)\n",
        "y_true = [label for label in test_dataset_encoded[\"label\"]]\n",
        "print(id_map)\n",
        "print(classification_report(y_true, y_preds, zero_division=0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ctUA5uaQ5Yjg",
        "outputId": "f7146b14-4ec0-48c7-b20f-9cb21b78deae"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0: 'Personality disorder', 1: 'Suicidal', 2: 'Depression', 3: 'Anxiety', 4: 'Normal', 5: 'Stress', 6: 'Bipolar'}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        72\n",
            "           1       0.52      0.68      0.59       302\n",
            "           2       0.52      0.47      0.49       309\n",
            "           3       0.46      0.55      0.50       239\n",
            "           4       0.64      0.93      0.76       289\n",
            "           5       0.47      0.37      0.42       182\n",
            "           6       0.76      0.10      0.18       153\n",
            "\n",
            "    accuracy                           0.54      1546\n",
            "   macro avg       0.48      0.44      0.42      1546\n",
            "weighted avg       0.53      0.54      0.50      1546\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing for custom input"
      ],
      "metadata": {
        "id": "w3C_a5d5AuEE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"I want to die.\"\n",
        "inputs = tokenizer(text, return_tensors=\"pt\")\n",
        "inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "outputs = model(**inputs)\n",
        "predictions = torch.argmax(outputs.logits, dim=1)\n",
        "predicted_label_id = predictions.item()\n",
        "print(f\"Predicted label ID: {predicted_label_id}\")\n",
        "print(f\"Predicted label: {id_map[predicted_label_id]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ey6zK7C28eM3",
        "outputId": "449cce2b-2486-429c-8e18-3c1f73b97580"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted label ID: 1\n",
            "Predicted label: Suicidal\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Today is another good day.\"\n",
        "inputs = tokenizer(text, return_tensors=\"pt\")\n",
        "inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "outputs = model(**inputs)\n",
        "predictions = torch.argmax(outputs.logits, dim=1)\n",
        "predicted_label_id = predictions.item()\n",
        "print(f\"Predicted label ID: {predicted_label_id}\")\n",
        "print(f\"Predicted label: {id_map[predicted_label_id]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q_pGGSNfNGaD",
        "outputId": "72b92d60-e7bb-4d7d-861f-4faa604ea54a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted label ID: 4\n",
            "Predicted label: Normal\n"
          ]
        }
      ]
    }
  ]
}